{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2dd9c5-4a01-4324-9652-15e8795414c3",
   "metadata": {},
   "source": [
    "<div style=\"position: absolute; top: 0; left: 0; font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <a href=\"https://github.com/patriciaapenat\" style=\"text-decoration: none; color: inherit;\">Patricia Peña Torres</a>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\" style=\"font-family: 'Garamond'; font-size: 48px;\">\n",
    "    <strong>Proyecto final, BRFSS-clustering</strong>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\" style=\"font-family: 'Garamond'; font-size: 36px;\">\n",
    "    <strong>Imputación de valores nulos</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996665d-371b-49eb-aed3-c9bdc041a87a",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79c08c-36ef-4bf1-9466-3c2fe33aee97",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal>Dado que trabajamos con una base de datos extensa, es crucial examinar detenidamente la documentación. En este caso, me basé en las fuentes oficiales de la BBDD para explorar los datos. Comencé revisando el cuestionario (<a href=\"https://www.cdc.gov/brfss/questionnaires/pdf-ques/2022-BRFSS-Questionnaire-508.pdf\" target=\"_blank\">disponible aquí</a>) pero hay mayor concordancia con el codebook (<a href=\"https://www.cdc.gov/brfss/annual_data/2022/zip/codebook22_llcp-v2-508.zip\" target=\"_blank\">disponible aquí</a>), donde se encuentran los códigos asociados a las preguntas y respuestas. Esta revisión es esencial para comprender las preguntas formuladas y facilita la eliminación de secciones no pertinentes.\n",
    "    En el presente notebook, llevé a cabo una revisión del documento mencionado, junto con el archivo de texto generado que contiene información sobre los valores nulos. La finalidad fue reducir con una limpieza rápida el dataset eliminando encuestas que no se habían completado o columnas que no utilizaremos.</normal>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950083c-0b8c-4835-9413-6fa62a1985ea",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 24px;\">\n",
    "    <strong>Importación de paquetes</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b597558-4d8e-4ba1-9bfe-71a7482505f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "import os.path\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "from pyspark.sql import DataFrame\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f5ac0-5401-4237-903b-5763e0ee97c6",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 24px;\">\n",
    "    <strong>Configuración de Spark</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c1edd3-f886-4c44-81bf-d6052444175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si hay un SparkContext existente, debemos cerrarlo antes de crear uno nuevo\n",
    "if 'sc' in locals() and sc:\n",
    "    sc.stop()  # Detener el SparkContext anterior si existe\n",
    "\n",
    "# Configuración de Spark\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setAppName(\"Proyecto_PatriciaA_Peña\")  # Nombre de la aplicación en Spark\n",
    "    .setMaster(\"local[1]\")  # Modo local con un hilo para ejecución\n",
    "    .set(\"spark.driver.host\", \"127.0.0.1\")  # Dirección del host del driver\n",
    "    .set(\"spark.executor.heartbeatInterval\", \"3600s\")  # Intervalo de latido del executor\n",
    "    .set(\"spark.network.timeout\", \"7200s\")  # Tiempo de espera de la red\n",
    "    .set(\"spark.executor.memory\", \"14g\")  # Memoria asignada para cada executor\n",
    "    .set(\"spark.driver.memory\", \"14g\")  # Memoria asignada para el driver\n",
    ")\n",
    "\n",
    "# Crear un nuevo SparkContext con la configuración especificada\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Configuración de SparkSession (interfaz de alto nivel para trabajar con datos estructurados en Spark)\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Proyecto_PatriciaA_Peña\")  # Nombre de la aplicación en Spark\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)  # Habilitar la evaluación perezosa en Spark SQL REPL\n",
    "    .config(\"spark.sql.repl.eagerEval.maxNumRows\", 1000)  # Número máximo de filas a mostrar en la evaluación perezosa\n",
    "    .getOrCreate()  # Obtener la sesión Spark existente o crear una nueva si no existe\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61069114-4bba-425b-b2ff-5e109d12fbe3",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 16px;\">\n",
    "    <strong>Lectura del archivo</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec195683-bd8e-4a86-ad35-2f831c3edd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV \n",
    "df = spark.read.csv(r\"C:\\\\Users\\\\patri\\\\OneDrive - UAB\\\\Documentos\\\\GitHub\\\\BRFSS-clustering\\\\datos\\\\BRFSS_Cleaner_2022.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18afbc2-4318-4baa-b757-c2c11acdd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir todas las columnas a tipo numérico\n",
    "for column_name in df.columns:\n",
    "    df = df.withColumn(column_name, col(column_name).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c201413-c794-44b1-9e3d-09e795f4c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_info_nulos_en_txt(df: DataFrame, archivo_nombre: str):\n",
    "    # Ruta del archivo de texto\n",
    "    file_path = f\"C:\\\\Users\\\\patri\\\\OneDrive - UAB\\\\Documentos\\\\GitHub\\\\BRFSS-clustering\\\\tratamiento\\\\{archivo_nombre}.txt\"\n",
    "\n",
    "    # Verifica si el archivo ya existe\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"¡Advertencia! El archivo '{file_path}' ya existe. No se ha sobrescrito. Por favor, elija otro nombre.\")\n",
    "        return\n",
    "    \n",
    "    # Abre el archivo en modo de escritura (crea uno nuevo)\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Escribe la cantidad de valores nulos por columna en el archivo\n",
    "        for col in df.columns:\n",
    "            null_count = df.filter(df[col].isNull() | (df[col] == \"\")).count()\n",
    "            file.write(f\"{col}: {null_count} valores nulos\\n\")\n",
    "\n",
    "    print(f\"La información sobre valores nulos del DataFrame '{archivo_nombre}' ha sido guardada en: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f2589-af1c-4e17-9f1a-ef1ddd9d5512",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal>\n",
    "Trabajamos con un dataset muy extenso así que por ello lo reduciremos en este notebook.</normal>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3026cd-8780-4010-87a0-b33470941549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La información sobre valores nulos del DataFrame 'nulos_3df' ha sido guardada en: C:\\Users\\patri\\OneDrive - UAB\\Documentos\\GitHub\\BRFSS-clustering\\tratamiento\\nulos_3df.txt\n"
     ]
    }
   ],
   "source": [
    "guardar_info_nulos_en_txt(df, \"nulos_3df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6544d436-a768-4d92-8ad9-7c3a2d3bd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf7115ea-b0a9-48a7-bf61-aa3534f2f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una columna de identificación utilizando el número de índice de las filas\n",
    "df = df.withColumn(\"ID\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8863c9ab-8aa0-4a1a-9ed9-2ccd5fe3f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mode_values_and_join(df_imputed, conditions_mode):\n",
    "    for col_name, condition in conditions_mode.items():\n",
    "        mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "        if isinstance(condition, bool):  \n",
    "            df_imputed = df_imputed.withColumn(col_name + '_imputed', lit(mode_value if condition else 0)) \n",
    "        else:\n",
    "            df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "    \n",
    "    df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac35d4f-21e6-4729-8637-25eb33336235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas para imputar con Imputer\n",
    "columns_to_impute = [\n",
    "    'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH',\n",
    "    'PRIMINSR', 'PERSDOC3', 'MEDCOST1', 'CHECKUP1', 'EXERANY2', 'SLEPTIM1', 'LASTDEN4',\n",
    "    'RMVTETH4', 'CVDINFR4', 'CVDCRHD4', 'CVDSTRK3', 'ASTHMA3', 'CHCSCNC1', 'CHCOCNC1',\n",
    "    'CHCCOPD3', 'ADDEPEV3', 'CHCKDNY2', 'HAVARTH4', 'DIABETE4', 'DIABAGE4', 'MARITAL',\n",
    "    'EDUCA', 'RENTHOM1', 'VETERAN3', 'EMPLOY1', 'INCOME', 'COPDCOGH', 'COPDFLEM',\n",
    "    'COPDBRTH', 'COPDBTST', 'COPDSMOK',\n",
    "    'DEAF', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON'\n",
    "]\n",
    "\n",
    "# Crear el imputer con estrategia 'mode' para imputar con la moda\n",
    "imputer = Imputer(\n",
    "    inputCols=columns_to_impute,\n",
    "    outputCols=[f\"{col}_imputed\" for col in columns_to_impute],  # Nombres de las columnas imputadas\n",
    "    strategy='mode'  # Utilizar la moda como estrategia de imputación\n",
    ")\n",
    "\n",
    "# Aplicar el imputer y transformar el DataFrame\n",
    "imputer_model = imputer.fit(df)\n",
    "df_imputed = imputer_model.transform(df)\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in columns_to_impute]), 'ID', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc907226-13cd-45c3-803c-d0f5e3df1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación con media para la columna CHILDREN\n",
    "mean_value = df.selectExpr('avg(CHILDREN) as mean_CHILDREN').collect()[0]['mean_CHILDREN']\n",
    "df_imputed = df_imputed.fillna(mean_value, subset=['CHILDREN']).withColumn('CHILDREN_imputed', col('CHILDREN').cast('double'))\n",
    "\n",
    "# Realizar el primer join\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in columns_to_impute]), 'ID', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819790c-a4b9-4862-8b3e-75c705e1188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salud ginecológica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656d8a4-86ab-47ec-8e27-77db4edce471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions_mode1 = {\n",
    "    \"ASTHNOW\": col(\"ASTHMA3\").isin([2, 7, 9]), #Esta es relativa a si el asma persiste,\n",
    "    \"HADMAM\": col(\"_SEX\") == 1,\n",
    "    \"HOWLONG\": col(\"_SEX\") == 1,\n",
    "    \"CERVSCRN\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLCNC\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLPAP\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLHPV\": col(\"_SEX\") == 1,\n",
    "    \"HADHYST2\": col(\"_SEX\") == 1,\n",
    "    \"PREGNANT\": col(\"_SEX\") == 1\n",
    "}\n",
    "\n",
    "df_imputed = impute_mode_values_and_join(df_imputed, conditions_mode)\n",
    "\n",
    "\n",
    "# Condiciones y cálculo de moda para las columnas HADSIGM4, COLNSIGM, LASTSIG4, COLNCNCR, VIRCOLO1, VCLNTES2, SMALSTOL, STOLTEST, STOOLDN2, BLDSTFIT, SDNATES1\n",
    "conditions_mode2 = {\n",
    "    'HADSIGM4': col(\"_AGE80\") < 45,\n",
    "    'COLNSIGM': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([1])) | (col(\"COLNSIGM\").isin([1, 7, 9, None])),\n",
    "    'LASTSIG4': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([2, 7, 9, None])) | (col(\"COLNSIGM\").isin([9, None])) | (col(\"SIGMTES1\").isNotNull()),\n",
    "    'COLNCNCR': col(\"_AGE80\") < 45,\n",
    "    'VIRCOLO1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'VCLNTES2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"VIRCOLO1\").isin([2, 7, 9])),\n",
    "    'SMALSTOL': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'STOLTEST': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"SMALSTOL\").isin([2, 7, 9, None])),\n",
    "    'STOOLDN2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'BLDSTFIT': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "    'SDNATES1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "}\n",
    "\n",
    "df_imputed = impute_mode_values_and_join(df_imputed, conditions_mode)\n",
    "\n",
    "# Condiciones y cálculo de moda para las columnas SMOKE100, SMOKDAY2, USENOW3, ECIGNOW2, LCSFIRST, LCSLAST, LCSNUMCG, LCSCTSC1, LCSSCNCR, LCSCTWHN\n",
    "conditions_mode = {\n",
    "    'SMOKE100': True,\n",
    "    'SMOKDAY2': col('SMOKE100').isin([2, 7, 9, None]),\n",
    "    'USENOW3': col('SMOKE100').isin([2, 7, 9, None]),\n",
    "    'ECIGNOW2': True,\n",
    "    'LCSFIRST': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]),\n",
    "    'LCSLAST': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]) | col('LCSFIRST').isin([888, None]),\n",
    "    'LCSNUMCG': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]) | col('LCSFIRST').isin([888, None]),\n",
    "    'LCSCTSC1': True,\n",
    "    'LCSSCNCR': col('LCSCTSC1').isin([2, 7, 9, None]),\n",
    "    'LCSCTWHN': col('LCSCTSC1').isin([2, 7, 9, None]) | col('LCSSCNCR').isin([2, 7, 9, None]),\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    if isinstance(condition, bool):  \n",
    "        df_imputed = df_imputed.withColumn(col_name + '_imputed', lit(mode_value if condition else 0)) \n",
    "    else:\n",
    "        df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "\n",
    "# Condiciones y cálculo de moda para las columnas FLUSHOT7, TETANUS1, PNEUVAC4, HIVTST7, HIVRISK5, COVIDPOS\n",
    "columns_to_impute_mode = ['FLUSHOT7', 'TETANUS1', 'PNEUVAC4', 'HIVTST7', 'HIVRISK5', 'COVIDPOS']\n",
    "\n",
    "for col_name in columns_to_impute_mode: \n",
    "    mode_value = df.groupBy(col_name).count().orderBy('count', ascending=False).first()[col_name] \n",
    "    df_imputed = df_imputed.withColumn(col_name + '_imputed', when(col(col_name).isNull(), mode_value).otherwise(col(col_name)))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in columns_to_impute_mode]), 'ID', 'left')\n",
    "\n",
    "\n",
    "pero usando esta función\n",
    "\n",
    "def impute_mode_values_and_join(df_imputed, conditions_mode):\n",
    "    for col_name, condition in conditions_mode.items():\n",
    "        mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "        if isinstance(condition, bool):  \n",
    "            df_imputed = df_imputed.withColumn(col_name + '_imputed', lit(mode_value if condition else 0)) \n",
    "        else:\n",
    "            df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "    \n",
    "    df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "    \n",
    "    return df_imputed\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c11cc19-79ab-474a-9fe8-f1900d187de0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from pyspark.sql.functions import col, mean, when\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df = df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Lista de columnas para imputar con Imputer\n",
    "columns_to_impute = [\n",
    "    'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH',\n",
    "    'PRIMINSR', 'PERSDOC3', 'MEDCOST1', 'CHECKUP1', 'EXERANY2', 'SLEPTIM1', 'LASTDEN4',\n",
    "    'RMVTETH4', 'CVDINFR4', 'CVDCRHD4', 'CVDSTRK3', 'ASTHMA3', 'CHCSCNC1', 'CHCOCNC1',\n",
    "    'CHCCOPD3', 'ADDEPEV3', 'CHCKDNY2', 'HAVARTH4', 'DIABETE4', 'DIABAGE4', 'MARITAL',\n",
    "    'EDUCA', 'RENTHOM1', 'VETERAN3', 'EMPLOY1', \n",
    "    'DEAF', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON'\n",
    "]\n",
    "\n",
    "# Crear el imputer con estrategia 'mode' para imputar con la moda\n",
    "imputer = Imputer(\n",
    "    inputCols=columns_to_impute,\n",
    "    outputCols=[f\"{col}_imputed\" for col in columns_to_impute],  # Nombres de las columnas imputadas\n",
    "    strategy='mode'  # Utilizar la moda como estrategia de imputación\n",
    ")\n",
    "\n",
    "# Aplicar el imputer y transformar el DataFrame\n",
    "imputer_model = imputer.fit(df)\n",
    "df_imputed = imputer_model.transform(df)\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in columns_to_impute]), 'ID', 'left')\n",
    "\n",
    "# Imputación con media para las columnas CHILDREN e INCOME3\n",
    "for col_name in ['CHILDREN', 'INCOME3']:\n",
    "    mean_value = df.selectExpr(f'avg({col_name}) as mean_{col_name}').collect()[0][f'mean_{col_name}']\n",
    "    df_imputed = df_imputed.fillna(mean_value, subset=[col_name]).withColumn(f\"{col_name}_imputed\", col(col_name).cast(\"double\"))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in columns_to_impute]), 'ID', 'left')\n",
    "\n",
    "# Condiciones y cálculo de moda para las columnas ASTHNOW, HADMAM, HOWLONG, CERVSCRN, CRVCLCNC, CRVCLPAP, CRVCLHPV, HADHYST2, PREGNANT\n",
    "conditions_mode = {\n",
    "    \"ASTHNOW\": col(\"ASTHMA3\").isin([2, 7, 9]),\n",
    "    \"HADMAM\": col(\"_SEX\") == 1,\n",
    "    \"HOWLONG\": col(\"_SEX\") == 1,\n",
    "    \"CERVSCRN\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLCNC\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLPAP\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLHPV\": col(\"_SEX\") == 1,\n",
    "    \"HADHYST2\": col(\"_SEX\") == 1,\n",
    "    \"PREGNANT\": col(\"_SEX\") == 1\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df_imputed = df_imputed.withColumn(f\"{col_name}_imputed\", when(condition, 0).otherwise(mode_value))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "\n",
    "# Condiciones y cálculo de moda para las columnas HADSIGM4, COLNSIGM, LASTSIG4, COLNCNCR, VIRCOLO1, VCLNTES2, SMALSTOL, STOLTEST, STOOLDN2, BLDSTFIT, SDNATES1\n",
    "conditions_mode = {\n",
    "    'HADSIGM4': col(\"_AGE80\") < 45,\n",
    "    'COLNSIGM': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([1])) | (col(\"COLNSIGM\").isin([1, 7, 9, None])),\n",
    "    'LASTSIG4': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([2, 7, 9, None])) | (col(\"COLNSIGM\").isin([9, None])) | (col(\"SIGMTES1\").isNotNull()),\n",
    "    'COLNCNCR': col(\"_AGE80\") < 45,\n",
    "    'VIRCOLO1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'VCLNTES2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"VIRCOLO1\").isin([2, 7, 9])),\n",
    "    'SMALSTOL': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'STOLTEST': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"SMALSTOL\").isin([2, 7, 9, None])),\n",
    "    'STOOLDN2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'BLDSTFIT': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "    'SDNATES1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, 0).otherwise(mode_value))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "\n",
    "# Condiciones y cálculo de moda para las columnas SMOKE100, SMOKDAY2, USENOW3, ECIGNOW2, LCSFIRST, LCSLAST, LCSNUMCG, LCSCTSC1, LCSSCNCR, LCSCTWHN\n",
    "conditions_mode = {\n",
    "    'SMOKE100': True,\n",
    "    'SMOKDAY2': col('SMOKE100').isin([2, 7, 9, None]),\n",
    "    'USENOW3': col('SMOKE100').isin([2, 7, 9, None]),\n",
    "    'ECIGNOW2': True,\n",
    "    'LCSFIRST': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]),\n",
    "    'LCSLAST': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]) | col('LCSFIRST').isin([888, None]),\n",
    "    'LCSNUMCG': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]) | col('LCSFIRST').isin([888, None]),\n",
    "    'LCSCTSC1': True,\n",
    "    'LCSSCNCR': col('LCSCTSC1').isin([2, 7, 9, None]),\n",
    "    'LCSCTWHN': col('LCSCTSC1').isin([2, 7, 9, None]) | col('LCSSCNCR').isin([2, 7, 9, None]),\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    if isinstance(condition, bool):  \n",
    "        df_imputed = df_imputed.withColumn(col_name + '_imputed', lit(mode_value if condition else 0)) \n",
    "    else:\n",
    "        df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "\n",
    "# Condiciones y cálculo de moda para las columnas FLUSHOT7, TETANUS1, PNEUVAC4, HIVTST7, HIVRISK5, COVIDPOS\n",
    "columns_to_impute_mode = ['FLUSHOT7', 'TETANUS1', 'PNEUVAC4', 'HIVTST7', 'HIVRISK5', 'COVIDPOS']\n",
    "\n",
    "for col_name in columns_to_impute_mode: \n",
    "    mode_value = df.groupBy(col_name).count().orderBy('count', ascending=False).first()[col_name] \n",
    "    df_imputed = df_imputed.withColumn(col_name + '_imputed', when(col(col_name).isNull(), mode_value).otherwise(col(col_name)))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in columns_to_impute_mode]), 'ID', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dadda3-607e-4f42-acc1-7aaa771f1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions_mode = {\n",
    "    'CNCRDIFF': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull(),\n",
    "    'CSRVTRT3': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull(),\n",
    "    'CSRVPAIN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull(),\n",
    "    'CSRVCTL2': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVPAIN').isin([2, 7, 9]) | col('CSRVPAIN').isNull(),\n",
    "    'CSRVDOC1': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVSUM': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVRTRN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVINST': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVINSR': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVDEIN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVCLIN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CNCRAGE': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CNCRDIFF').isin([7, 9]) | col('CNCRDIFF').isNull(),\n",
    "    'CNCRTYP2': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CNCRDIFF').isin([7, 9]) | col('CNCRDIFF').isNull()\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "                \n",
    "conditions_mode = {\n",
    "    'PSATEST1': (col('_SEX') == 1) | (col('_AGE80') < 40),\n",
    "    'PSASUGST': (col('_SEX') == 1) | (col('_AGE80') < 40),\n",
    "    'PCSTALK1': (col('_SEX') == 1) | (col('_AGE80') < 40),\n",
    "    'PCPSARS2': (col('_SEX') == 1) | (col('_AGE80') < 40) | col('PSATEST1').isin([2, 7, 9]) | col('PSATEST1').isNull(),\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "\n",
    "conditions_mode = {\n",
    "    'CIMEMLOS': col('_AGE80') < 45,\n",
    "    'CDHOUSE': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDASSIST': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDSOCIAL': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDDISCUS': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDHELP': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]) | col('CDASSIST').isin([4, 5, 7, 9]),\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n",
    "\n",
    "# Condiciones y cálculo de moda para las nuevas columnas\n",
    "conditions_mode = {\n",
    "    'CAREGIV1': True,\n",
    "    'CRGVREL4': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVLNG1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVEXPT': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVPER1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVHOU1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVHRS1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVPRB3': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVALZD': (col('CAREGIV1').isin([2, 8, 7, 9])) | (col('CRGVPRB3') == 5),\n",
    "}\n",
    "\n",
    "for col_name, condition in conditions_mode.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    if isinstance(condition, bool):  \n",
    "        df_imputed = df_imputed.withColumn(col_name + '_imputed', lit(mode_value if condition else 0)) \n",
    "    else:\n",
    "        df_imputed = df_imputed.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n",
    "\n",
    "df_imputed = df_imputed.join(df_imputed.select('ID', *[f\"{col}_imputed\" for col in conditions_mode.keys()]), 'ID', 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7b9aa-a1de-4f09-a7a9-333605fd39a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4a3a50e9-3a48-4b34-8c54-13f1ca3238d4",
   "metadata": {},
   "source": [
    "# Eliminar las columnas imputadas y la columna de identificación temporal\n",
    "df_final = df_final.drop(*[col for col in df_imputed.columns if col.endswith(\"_imputed\")]).drop(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0666f8-1f8c-4c7f-b30c-b8c123ebf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2ab58a1-54ea-4610-a90a-dae974188a69",
   "metadata": {},
   "source": [
    "guardar_info_nulos_en_txt(df, \"nulos_4df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa105eae-d0bb-4f98-957d-22dc17a42705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291a2aa-1b07-4c43-9cc1-b60105dd795c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7faa18f3-a4e2-455c-809f-494c54546036",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Lista de columnas que quieres imputar con la moda\n",
    "columns_to_impute = [\n",
    "    'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH',\n",
    "    'PRIMINSR', 'PERSDOC3', 'MEDCOST1', 'CHECKUP1', 'EXERANY2', 'SLEPTIM1', 'LASTDEN4',\n",
    "    'RMVTETH4', 'CVDINFR4', 'CVDCRHD4', 'CVDSTRK3', 'ASTHMA3', 'CHCSCNC1', 'CHCOCNC1',\n",
    "    'CHCCOPD3', 'ADDEPEV3', 'CHCKDNY2', 'HAVARTH4', 'DIABETE4', 'DIABAGE4', 'MARITAL',\n",
    "    'EDUCA', 'RENTHOM1', 'VETERAN3', 'EMPLOY1', \n",
    "    'DEAF', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON'\n",
    "]\n",
    "\n",
    "# Crear el imputer\n",
    "imputer = Imputer(\n",
    "    inputCols=columns_to_impute,\n",
    "    outputCols=[f\"{col}_imputed\" for col in columns_to_impute]  # Nombres de las columnas imputadas\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79d2494b-0eee-40b5-b3db-a932e3e33031",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Lista de columnas que quieres imputar con la media\n",
    "columns_to_impute = ['CHILDREN', 'INCOME3']\n",
    "\n",
    "# Crear el imputer\n",
    "imputer = Imputer(\n",
    "    inputCols=columns_to_impute,\n",
    "    outputCols=[f\"{col}_imputed\" for col in columns_to_impute],  # Nombres de las columnas imputadas\n",
    "    strategy='mean'  # Utilizar la estrategia de imputación por media\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b750342-5ea2-41f5-8dfb-f5b26d4d48d9",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Calcular la moda de la columna ASTHNOW\n",
    "mode_value = df.select('ASTHNOW').groupBy('ASTHNOW').count().orderBy('count', ascending=False).first()[0]\n",
    "\n",
    "# Imputar valores nulos en ASTHNOW\n",
    "df_imputed = df.withColumn(\"ASTHNOW_imputed\", when(col(\"ASTHMA3\").isin([2, 7, 9]), 0).otherwise(mode_value))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ffb9919-e212-4ee7-884e-3aed65ab18a5",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Lista de columnas a imputar\n",
    "columns_to_impute = ['HADMAM', 'HOWLONG', 'CERVSCRN', 'CRVCLCNC', 'CRVCLPAP', 'CRVCLHPV', 'HADHYST2', 'PREGNANT']\n",
    "\n",
    "# Imputar valores nulos con condición\n",
    "for col_name in columns_to_impute:\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df = df.withColumn(col_name + '_imputed', when(col(\"_SEX\") == 1, 0).otherwise(mode_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8909d9-a2f8-43ea-afa8-005d4aca4ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "73ab5acc-c063-4502-8e07-b8e0e10ea4d0",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Definir las condiciones para cada columna\n",
    "conditions = {\n",
    "    'HADSIGM4': col(\"_AGE80\") < 45,\n",
    "    'COLNSIGM': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([1])) | (col(\"COLNSIGM\").isin([1, 7, 9, None])),\n",
    "    'LASTSIG4': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([2, 7, 9, None])) | (col(\"COLNSIGM\").isin([9, None])) | (col(\"SIGMTES1\").isNotNull()),\n",
    "    'COLNCNCR': col(\"_AGE80\") < 45,\n",
    "    'VIRCOLO1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'VCLNTES2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"VIRCOLO1\").isin([2, 7, 9])),\n",
    "    'SMALSTOL': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'STOLTEST': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"SMALSTOL\").isin([2, 7, 9, None])),\n",
    "    'STOOLDN2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'BLDSTFIT': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "    'SDNATES1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "}\n",
    "\n",
    "# Imputar valores nulos\n",
    "for col_name, condition in conditions.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df = df.withColumn(col_name + '_imputed', when(condition, 0).otherwise(mode_value))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2639bcd4-8209-4d32-91c1-8df40865b7a5",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Definir las condiciones para cada columna\n",
    "conditions = {\n",
    "    'SMOKE100': True,\n",
    "    'SMOKDAY2': col('SMOKE100').isin([2, 7, 9, None]),\n",
    "    'USENOW3': col('SMOKE100').isin([2, 7, 9, None]),\n",
    "    'ECIGNOW2': True,\n",
    "    'LCSFIRST': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]),\n",
    "    'LCSLAST': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]) | col('LCSFIRST').isin([888, None]),\n",
    "    'LCSNUMCG': col('SMOKE100').isin([2, 7, 9, None]) | col('SMOKDAY2').isin([7, 9, None]) | col('LCSFIRST').isin([888, None]),\n",
    "    'LCSCTSC1': True,\n",
    "    'LCSSCNCR': col('LCSCTSC1').isin([2, 7, 9, None]),\n",
    "    'LCSCTWHN': col('LCSCTSC1').isin([2, 7, 9, None]) | col('LCSSCNCR').isin([2, 7, 9, None]),\n",
    "}\n",
    "\n",
    "# Imputar valores nulos con 0 si la condición no se cumple, de lo contrario, con la moda\n",
    "for col_name, condition in conditions.items():\n",
    "    mode_value = df.groupBy().agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    df = df.withColumn(col_name + '_imputed', when(condition, mode_value).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef460dd0-8c17-43f1-8340-948a4f76bb26",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Calcular la moda de la columna ALCDAY4\n",
    "mode_value_ALCDAY4 = df.select('ALCDAY4').groupBy('ALCDAY4').count().orderBy('count', ascending=False).first()[0]\n",
    "\n",
    "# Imputar valores nulos en ALCDAY4 con la moda de la columna\n",
    "df_imputed = df.withColumn(\"ALCDAY4_imputed\", when(col(\"ALCDAY4\").isNull(), mode_value_ALCDAY4).otherwise(col(\"ALCDAY4\")))\n",
    "\n",
    "# Imputar valores nulos en AVEDRNK3, DRNK3GE5, MAXDRNKS\n",
    "for col_name in [\"AVEDRNK3\", \"DRNK3GE5\", \"MAXDRNKS\"]:\n",
    "    mean_value = df_imputed.selectExpr(f\"avg({col_name}) as mean_{col_name}\").collect()[0][f\"mean_{col_name}\"]\n",
    "    df_imputed = df_imputed.withColumn(f\"{col_name}_imputed\", when(col(\"ALCDAY4\").isin([888, 777, 999]), 0).otherwise(mean_value))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08f3346e-d58d-4e1c-8efc-8c07574d8b4f",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Lista de columnas a imputar\n",
    "columns_to_impute = ['FLUSHOT7', 'TETANUS1', 'PNEUVAC4']\n",
    "\n",
    "# Imputar valores nulos con la moda de la columna\n",
    "for col_name in columns_to_impute:\n",
    "    mode_value = df.groupBy(col_name).count().orderBy('count', ascending=False).first()[col_name]\n",
    "    df = df.withColumn(col_name + '_imputed', col(col_name).fillna(mode_value))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a329a707-2a89-4e8d-8923-725cfd3ebef1",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Columnas a imputar\n",
    "columns_to_impute = ['HIVTST7', 'HIVRISK5']\n",
    "\n",
    "# Imputar valores nulos con la moda de la columna\n",
    "for col_name in columns_to_impute:\n",
    "    mode_value = df.groupBy(col_name).count().orderBy('count', ascending=False).first()[col_name]\n",
    "    df = df.withColumn(col_name + '_imputed', col(col_name).fillna(mode_value))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef7df88e-943b-4089-b8a9-fc3cfc36e69e",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Calcular la moda de la columna COVIDPOS\n",
    "mode_value_covidpos = df.select('COVIDPOS').groupBy('COVIDPOS').count().orderBy('count', ascending=False).first()[0]\n",
    "\n",
    "# Imputar valores nulos en COVIDPOS con la moda de la columna\n",
    "df_imputed = df.withColumn(\"COVIDPOS_imputed\", col(\"COVIDPOS\").fillna(mode_value_covidpos))\n",
    "\n",
    "# Calcular la media de las columnas COVIDSMP y COVIDPRM\n",
    "mean_covidsmp = df_imputed.selectExpr('avg(COVIDSMP) as mean_covidsmp').collect()[0]['mean_covidsmp']\n",
    "mean_covidprm = df_imputed.selectExpr('avg(COVIDPRM) as mean_covidprm').collect()[0]['mean_covidprm']\n",
    "\n",
    "# Imputar valores nulos en COVIDSMP y COVIDPRM\n",
    "for col_name, mean_value in [(\"COVIDSMP\", mean_covidsmp), (\"COVIDPRM\", mean_covidprm)]:\n",
    "    df_imputed = df_imputed.withColumn(f\"{col_name}_imputed\", when((col(\"COVIDPOS\").isin([2, 7, 9, None])) | (col(\"COVIDSMP\").isin([2, 7, 9, None]) if col_name == \"COVIDPRM\" else False), 0).otherwise(mean_value))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0f36bbb-4882-457b-9487-926b7925b403",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Calcular la moda de la columna DIABETE4\n",
    "mode_value_diabete4 = df.select('DIABETE4').groupBy('DIABETE4').count().orderBy('count', ascending=False).first()[0]\n",
    "\n",
    "# Imputar valores nulos en DIABETE4 con la moda de la columna\n",
    "df_imputed = df.withColumn(\"DIABETE4_imputed\", col(\"DIABETE4\").fillna(mode_value_diabete4))\n",
    "\n",
    "# Condiciones para imputación\n",
    "conditions = {\n",
    "    \"PDIABTS1\": col(\"DIABETE4\") == 1,\n",
    "    \"PREDIAB2\": when(col(\"DIABETE4\") == 1, 0).when(col(\"DIABETE4\") == 4, 1),\n",
    "    \"DIABTYPE\": col(\"DIABETE4\").isin([2, 3, 4, 7, 9]),\n",
    "    \"INSULIN1\": col(\"DIABETE4\").isin([2, 3, 4, 7, 9]),\n",
    "    \"CHKHEMO3\": col(\"DIABETE4\").isin([2, 3, 4, 7, 9]),\n",
    "    \"EYEEXAM1\": col(\"DIABETE4\").isin([2, 3, 4, 7, 9]),\n",
    "    \"DIABEYE1\": col(\"DIABETE4\").isin([2, 3, 4, 7, 9]),\n",
    "    \"DIABEDU1\": col(\"DIABETE4\").isin([2, 3, 4, 7, 9]),\n",
    "    \"FEETSORE\": col(\"DIABETE4\").isin([2, 3, 4, 7, 9])\n",
    "}\n",
    "\n",
    "# Imputar valores nulos en columnas según condiciones\n",
    "for col_name, condition in conditions.items():\n",
    "    df_imputed = df_imputed.withColumn(f\"{col_name}_imputed\", when(condition, 0).otherwise(mode_value_diabete4))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abef840a-32e7-4e14-99e6-36bba01d5eb5",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Condiciones para imputación\n",
    "conditions = {\n",
    "    \"IMFVPLA3\": col(\"FLUSHOT7\").isin([2, 7, 9]),\n",
    "    \"HPVADVC4\": col(\"_AGE80\") > 49,\n",
    "    \"HPVADSHT\": (col(\"_AGE80\") > 49) | col(\"HPVADVC4\").isin([2, 3, 7, 9, None]),\n",
    "    \"HPVADSHT\": col(\"_AGE80\") > 50\n",
    "}\n",
    "\n",
    "# Calcular la moda de la columna correspondiente para cada caso\n",
    "mode_values = {}\n",
    "for col_name, condition in conditions.items():\n",
    "    if condition:\n",
    "        mode_values[col_name] = df.select(col_name).groupBy(col_name).count().orderBy('count', ascending=False).first()[col_name]\n",
    "\n",
    "# Imputar valores nulos según las condiciones\n",
    "df_imputed = df\n",
    "for col_name, condition in conditions.items():\n",
    "    if condition:\n",
    "        df_imputed = df_imputed.withColumn(col_name + \"_imputed\", when(condition, 0).otherwise(mode_values[col_name]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ed3c8cc-0b21-4f0d-abcc-506692b3b3b2",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Definir condiciones para imputación\n",
    "conditions = {\n",
    "    \"COVIDVA1\": df.select(\"COVIDVA1\").groupBy(\"COVIDVA1\").count().orderBy(\"count\", ascending=False).first()[0],\n",
    "    \"COVACGET\": when(col(\"COVIDVA1\").isin([1, 7, 9, None]), 0).otherwise(df.select(\"COVACGET\").groupBy(\"COVACGET\").count().orderBy(\"count\", ascending=False).first()[0]),\n",
    "    \"COVIDNU1\": when(col(\"COVIDVA1\").isin([1, 7, 9, None]) | col(\"COVACGET\").isNotNull(), 0).otherwise(df.select(\"COVIDNU1\").groupBy(\"COVIDNU1\").count().orderBy(\"count\", ascending=False).first()[0]),\n",
    "    \"COVIDINT\": when(col(\"COVIDVA1\").isin([1, 7, 9, None]) | col(\"COVACGET\").isNotNull() | col(\"COVIDNU1\").isin([2, 3, 4, None]), 0).otherwise(df.select(\"COVIDINT\").groupBy(\"COVIDINT\").count().orderBy(\"count\", ascending=False).first()[0])\n",
    "}\n",
    "\n",
    "# Imputar valores nulos según las condiciones\n",
    "df_imputed = df\n",
    "for col_name, condition in conditions.items():\n",
    "    df_imputed = df_imputed.withColumn(col_name + \"_imputed\", condition)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cc0a7f5-5743-48dd-b5fb-bbf906722a5e",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, mean\n",
    "\n",
    "# Calcular la moda de las columnas COPDCOGH, COPDFLEM, COPDBRTH y COPDBTST\n",
    "mode_values = {col_name: df.select(col_name).groupBy(col_name).count().orderBy('count', ascending=False).first()[col_name] for col_name in ['COPDCOGH', 'COPDFLEM', 'COPDBRTH', 'COPDBTST']}\n",
    "\n",
    "# Imputar valores nulos en COPDCOGH, COPDFLEM, COPDBRTH y COPDBTST con la moda de cada columna\n",
    "df_imputed = df\n",
    "for col_name, mode_value in mode_values.items():\n",
    "    df_imputed = df_imputed.withColumn(col_name + \"_imputed\", col(col_name).fillna(mode_value))\n",
    "\n",
    "# Calcular la media de la columna COPDSMOK\n",
    "mean_value_copdsmok = df.selectExpr('avg(COPDSMOK) as mean_copdsmok').collect()[0]['mean_copdsmok']\n",
    "\n",
    "# Imputar valores nulos en COPDSMOK con la media de la columna\n",
    "df_imputed = df_imputed.withColumn(\"COPDSMOK_imputed\", col(\"COPDSMOK\").fillna(mean_value_copdsmok))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef17257-3381-4a0e-aee5-371d4201ed73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd25e5-c141-4ebf-a45e-b22139def181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
