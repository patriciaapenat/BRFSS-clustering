{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2dd9c5-4a01-4324-9652-15e8795414c3",
   "metadata": {},
   "source": [
    "<div style=\"position: absolute; top: 0; left: 0; font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <a href=\"https://github.com/patriciaapenat\" style=\"text-decoration: none; color: inherit;\">Patricia Peña Torres</a>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\" style=\"font-family: 'Garamond'; font-size: 48px;\">\n",
    "    <strong>Proyecto final, BRFSS-clustering</strong>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\" style=\"font-family: 'Garamond'; font-size: 36px;\">\n",
    "    <strong>Imputación de valores nulos</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996665d-371b-49eb-aed3-c9bdc041a87a",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a824e7-697e-497f-9146-14902620a8d7",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "\n",
    "Este notebook aborda la imputación de valores nulos, un paso crítico en el preprocesamiento de datos para análisis de clustering. Se utilizan técnicas específicas para tratar valores nulos basándose en las características de cada columna, incluyendo la imputación basada en la media y la mediana, y se aplican condiciones personalizadas para determinar cómo se deben imputar ciertos valores, reflejando la complejidad y la especificidad de los datos de salud pública.\n",
    "\n",
    "\n",
    "Se concluye con la imputación de los datos y la exportación del DataFrame resultante para su análisis posterior. Este flujo de trabajo detallado y meticuloso muestra la aplicación de Spark para el análisis de grandes volúmenes de datos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950083c-0b8c-4835-9413-6fa62a1985ea",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 24px;\">\n",
    "    <strong>Importación de paquetes</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b597558-4d8e-4ba1-9bfe-71a7482505f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, DataFrame, functions as F, Window\n",
    "from pyspark.sql.functions import col, mean, when, lit, monotonically_increasing_id\n",
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f5ac0-5401-4237-903b-5763e0ee97c6",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 24px;\">\n",
    "    <strong>Configuración de Spark</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c1edd3-f886-4c44-81bf-d6052444175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si hay un SparkContext existente, debemos cerrarlo antes de crear uno nuevo\n",
    "if 'sc' in locals() and sc:\n",
    "    sc.stop()  # Detener el SparkContext anterior si existe\n",
    "\n",
    "# Configuración de Spark\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setAppName(\"Proyecto_PatriciaA_Peña\")  # Nombre de la aplicación en Spark\n",
    "    .setMaster(\"local[2]\")  # Modo local con un hilo para ejecución\n",
    "    .set(\"spark.driver.host\", \"127.0.0.1\")  # Dirección del host del driver\n",
    "    .set(\"spark.executor.heartbeatInterval\", \"3600s\")  # Intervalo de latido del executor\n",
    "    .set(\"spark.network.timeout\", \"7200s\")  # Tiempo de espera de la red\n",
    "    .set(\"spark.executor.memory\", \"14g\")  # Memoria asignada para cada executor\n",
    "    .set(\"spark.driver.memory\", \"14g\")  # Memoria asignada para el driver\n",
    ")\n",
    "\n",
    "# Crear un nuevo SparkContext con la configuración especificada\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Configuración de SparkSession (interfaz de alto nivel para trabajar con datos estructurados en Spark)\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Proyecto_PatriciaA_Peña\")  # Nombre de la aplicación en Spark\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)  # Habilitar la evaluación perezosa en Spark SQL REPL\n",
    "    .config(\"spark.sql.repl.eagerEval.maxNumRows\", 1000)  # Número máximo de filas a mostrar en la evaluación perezosa\n",
    "    .getOrCreate()  # Obtener la sesión Spark existente o crear una nueva si no existe\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61069114-4bba-425b-b2ff-5e109d12fbe3",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 16px;\">\n",
    "    <strong>Lectura del archivo</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec195683-bd8e-4a86-ad35-2f831c3edd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV \n",
    "df = spark.read.csv(r\"C:\\\\Users\\\\patri\\\\OneDrive - UAB\\\\Documentos\\\\GitHub\\\\BRFSS-clustering\\\\datos\\\\BRFSS_Cleaner_2022.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18afbc2-4318-4baa-b757-c2c11acdd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte todas las columnas a tipo double\n",
    "df = df.select(*[col(column_name).cast(\"double\").alias(column_name) for column_name in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe19152-7bd9-4e8a-8a9f-47e6c1a83525",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 20px;\">\n",
    "    <strong>Imputación de nulos</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f2589-af1c-4e17-9f1a-ef1ddd9d5512",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal>\n",
    "Trabajamos con un dataset que como hemos comentado proviene de encuestas, así que hay una enorme cantidad de valores nulos, esto lo abordaremos columna a columna, fue necesario hacer una revisión minuciosa del dataset y del codebook para establecer las necesidades específicas que podía tener cada columna, este proceso fue lento pero necesario para poder contar con datos limpios y sin datos nulos.</normal> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8e458f-97eb-4e1e-bf98-8602e7fd20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a considerar como NA\n",
    "na_values = [9, 99, 88]  # Esta es la clave para \"Refused\"\n",
    "\n",
    "# Marcar valores 9 o 99 como NA en todas las columnas (excepto _AGE80, _FMONTH y _STATE)\n",
    "for col_name in df.columns:\n",
    "    if col_name not in [\"_AGE80\", \"_FMONTH\", \"_STATE\"]: \n",
    "        df = df.withColumn(col_name, when(col(col_name).isin(na_values), None).otherwise(col(col_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0713f703-62c8-4374-9218-3ec7545c0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = { # Había muchas más secciones como por ejemplo determinantes sociales, dificultades en la infancia, consumo de cannabis, etc.\n",
    "               # así mismo había muchas más columnas de secciones como salud respiratoria pero al ser columnas que no tenían condiciones especiales\n",
    "               # se trataron conjunto a otras con las misma necesidades\n",
    "    # Salud ginecológica\n",
    "    \"HADMAM\": col(\"_SEX\") == 1,\n",
    "    \"HOWLONG\": col(\"_SEX\") == 1,\n",
    "    \"CERVSCRN\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLCNC\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLPAP\": col(\"_SEX\") == 1,\n",
    "    \"CRVCLHPV\": col(\"_SEX\") == 1,\n",
    "    \"HADHYST2\": col(\"_SEX\") == 1,\n",
    "    \"PREGNANT\": col(\"_SEX\") == 1,\n",
    "    # Cáncer colorectal\n",
    "    'HADSIGM4': col(\"_AGE80\") < 45,\n",
    "    'COLNSIGM': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([1])) | (col(\"COLNSIGM\").isin([1, 7, 9, None])),\n",
    "    'LASTSIG4': (col(\"_AGE80\") < 45) | (col(\"HADSIGM4\").isin([2, 7, 9, None])) | (col(\"COLNSIGM\").isin([9, None])) | (col(\"SIGMTES1\").isNotNull()),\n",
    "    'COLNCNCR': col(\"_AGE80\") < 45,\n",
    "    'VIRCOLO1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'VCLNTES2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"VIRCOLO1\").isin([2, 7, 9])),\n",
    "    'SMALSTOL': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'STOLTEST': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"SMALSTOL\").isin([2, 7, 9, None])),\n",
    "    'STOOLDN2': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])),\n",
    "    'BLDSTFIT': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "    'SDNATES1': (col(\"_AGE80\") < 45) | (col(\"COLNCNCR\").isin([2, 7, 9, None])) | (col(\"STOOLDN2\").isin([2, 7, 9, None])),\n",
    "    # Hábito tabáquico\n",
    "    'LCSFIRST': col('SMOKE100').isin([2, 7, 9]) | col('SMOKDAY2').isin([7, 9]),\n",
    "    'LCSLAST': col('SMOKE100').isin([2, 7, 9]) | col('SMOKDAY2').isin([7, 9]) | col('LCSFIRST').isin([888]),\n",
    "    'LCSNUMCG': col('SMOKE100').isin([2, 7, 9]) | col('SMOKDAY2').isin([7, 9]) | col('LCSFIRST').isin([888]),\n",
    "    'LCSSCNCR': col('LCSCTSC1').isin([2, 7, 9]),\n",
    "    'LCSCTWHN': col('LCSCTSC1').isin([2, 7, 9]) | col('LCSSCNCR').isin([2, 7, 9]),\n",
    "    'STOPSMK2': (col('SMOKE100').isin([2, 7, 9])) | (col('SMOKDAY2').isin([1, 2, 7, 9])),\n",
    "    'LASTSMK2': (col('SMOKE100').isin([2, 7, 9])) | (col('SMOKDAY2').isin([1, 2, 7, 9])) | (col('LASTSMK2').isNull()),\n",
    "    'MENTCIGS': col('SMOKDAY2').isin([1, 2, 7, 9]),\n",
    "    'MENTECIG': (col('SMOKDAY2').isin([1, 2, 7, 9])) | (col('ECIGNOW2').isin([1, 4, 7, 9])),\n",
    "    # Cáncer, sobrevivencia y manejo del dolor \n",
    "    'CNCRDIFF': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull(),\n",
    "    'CSRVTRT3': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull(),\n",
    "    'CSRVPAIN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull(),\n",
    "    'CSRVCTL2': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVPAIN').isin([2, 7, 9]) | col('CSRVPAIN').isNull(),\n",
    "    'CSRVDOC1': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVSUM': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVRTRN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVINST': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVINSR': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVDEIN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CSRVCLIN': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CSRVTRT3').isin([1, 3, 4, 5, 7, 9]) | col('CSRVTRT3').isNull(),\n",
    "    'CNCRAGE': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CNCRDIFF').isin([7, 9]) | col('CNCRDIFF').isNull(),\n",
    "    'CNCRTYP2': col('CHCSCNC1').isin([2, 7, 9]) | col('CHCOCNC1').isin([2, 7, 9]) | col('CHCSCNC1').isNull() | col('CHCOCNC1').isNull() | col('CNCRDIFF').isin([7, 9]) | col('CNCRDIFF').isNull(),\n",
    "    # Cáncer prostático\n",
    "    'PSATEST1': (col('_SEX') == 1) | (col('_AGE80') < 40),\n",
    "    'PSASUGST': (col('_SEX') == 1) | (col('_AGE80') < 40),\n",
    "    'PCSTALK1': (col('_SEX') == 1) | (col('_AGE80') < 40),\n",
    "    'PCPSARS2': (col('_SEX') == 1) | (col('_AGE80') < 40) | col('PSATEST1').isin([2, 7, 9]) | col('PSATEST1').isNull(),\n",
    "    # Dependencia funcional\n",
    "    'CIMEMLOS': col('_AGE80') < 45,\n",
    "    'CDHOUSE': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDASSIST': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDSOCIAL': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDDISCUS': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]),\n",
    "    'CDHELP': (col('_AGE80') < 45) | col('CIMEMLOS').isin([2, 9]) | col('CDASSIST').isin([4, 5, 7, 9]),\n",
    "    # Red de apoyo y cuidados\n",
    "    'CRGVREL4': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVLNG1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVEXPT': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVPER1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVHOU1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVHRS1': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVPRB3': col('CAREGIV1').isin([2, 8, 7, 9]),\n",
    "    'CRGVALZD': (col('CAREGIV1').isin([2, 8, 7, 9])) | (col('CRGVPRB3') == 5),\n",
    "    # Salud respiratoria\n",
    "    'ASTHNOW': col('ASTHMA3').isin([2, 7, 9]),\n",
    "    # Consumo de alcohol\n",
    "    'ASBIALCH': col('CHECKUP1').isin([3, 4, 7, 8, 9, None]),\n",
    "    'ASBIDRNK': col('CHECKUP1').isin([3, 4, 7, 8, 9, None]),\n",
    "    'ASBIBING': col('CHECKUP1').isin([3, 4, 7, 8, 9, None]),\n",
    "    'ASBIADVC': col('CHECKUP1').isin([3, 4, 7, 8, 9, None]),\n",
    "    'ASBIRDUC': (col('CHECKUP1').isin([3, 4, 7, 8, 9, None]) |  col('ASBIALCH').isin([2, 7, 9, None]) | col('ASBIDRNK').isin([2, 7, 9, None]) | col('ASBIBING').isin([2, 7, 9, None])),\n",
    "    # Armas de fuego\n",
    "    'GUNLOAD': col('FIREARM5').isin([2, 7, 9, None]),\n",
    "    'LOADULK2': (col('FIREARM5').isin([2, 7, 9, None]) | col('GUNLOAD').isin([2, 7, 9, None])),\n",
    "}\n",
    "\n",
    "# Aplicar condiciones para rellenar con ceros donde se cumpla la condición\n",
    "for col_name, condition in conditions.items():\n",
    "    df = df.withColumn(col_name, F.when(condition & df[col_name].isNull(), 0).otherwise(df[col_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b986e-ced5-4d2d-9669-1ddd9e546f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal>\n",
    "Tratamiento específico para columnas que explícitamente necesitaremos la media y no la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd8c5fd-e051-4cf5-998b-c20f39bdfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value_children = df.groupBy().agg(F.mean('CHILDREN').alias('mean_CHILDREN')).collect()[0]['mean_CHILDREN']\n",
    "df = df.fillna(mean_value_children, subset=['CHILDREN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f474315-ed2c-44e8-92dc-b6ea76d2f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value_bmi5 = df.groupBy().agg(F.mean('_BMI5').alias('mean_bmi5')).collect()[0]['mean_bmi5']\n",
    "df = df.fillna(mean_value_bmi5, subset=['_BMI5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3baa91-7663-4576-a8ff-fe0519ee464b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal> Todas las columnas restantes las completaremos con la mediana de la misma, la idea inicial era usar la moda pero no era viable con el método Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b460b56c-0b6a-4b16-b5f1-074c4601bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, se especifica las columnas a las que se desea aplicar el Imputer\n",
    "input_columns = [col for col in df.columns if df.filter(df[col].isNull()).count() > 0]\n",
    "output_columns = input_columns  # En este caso, sobrescribiremos las columnas originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d0a5c95-7fad-4fdf-87ce-89b673fae878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el Imputer para imputar los valores nulos con la mediana\n",
    "imputer = Imputer(\n",
    "    strategy='median',\n",
    "    inputCols=input_columns,\n",
    "    outputCols=output_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d433ad-9682-4588-abcb-9ced7236c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el imputer y transformar el DataFrame\n",
    "imputer_model = imputer.fit(df)\n",
    "df = imputer_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122506d-97f4-4c2c-8e35-d505d467d6cb",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal>\n",
    "Revisamos si quedan valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0158c93b-a647-4252-9f42-a9429cb0efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime las columnas con valores nulos\n",
    "for col in df.columns:\n",
    "    null_count = df.where(df[col].isNull()).count()\n",
    "    if null_count > 0:\n",
    "        print(f\"La columna '{col}' tiene {null_count} valores nulos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e49c5-559e-4e1d-ad14-a58d74ab8923",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal>\n",
    "Y por último exportamos el csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8024650b-211b-48bd-bf20-ca10e618279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como CSV\n",
    "df.write.csv(\"C:\\\\Users\\\\patri\\\\OneDrive - UAB\\\\Documentos\\\\GitHub\\\\BRFSS-clustering\\\\datos\\\\BRFSS_Imputated_2022.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70ebef-5469-4cfa-98a0-2323d672db86",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Garamond'; font-size: 14px;\">\n",
    "    <normal>\n",
    "        \n",
    "Este notebook es parte de un proyecto enfocado en la aplicación de algoritmos de clustering a las encuestas BRFSS (Behavioral Risk Factor Surveillance System). El BRFSS es una encuesta telefónica realizada por los CDC (Centros para el Control y la Prevención de Enfermedades) que recopila datos sobre factores de riesgo de comportamiento entre adultos en los Estados Unidos. Este proyecto busca analizar y agrupar estos datos para identificar patrones y tendencias que puedan informar decisiones de políticas de salud pública.\n",
    "\n",
    "El código comienza con la configuración del entorno de Spark, utilizando `SparkConf` y `SparkContext` para establecer parámetros como el nombre de la aplicación, configuraciones de memoria, y otros aspectos relevantes para la ejecución eficiente de operaciones de Spark. Se hace uso de `SparkSession`, una interfaz de alto nivel para Spark SQL y DataFrame API, facilitando la manipulación de datos estructurados.\n",
    "\n",
    "La lectura de datos se realiza desde un archivo CSV que contiene datos limpios de la encuesta BRFSS. Este archivo es cargado en un DataFrame de Spark, donde cada columna es convertida al tipo de dato `double` para facilitar su análisis numérico. \n",
    "\n",
    "Una parte crucial del preprocesamiento es la gestión de valores nulos y atípicos, marcando específicamente valores como 9 o 99 (que en este contexto se interpretan como respuestas tipo \"Refused\") como nulos, excepto en columnas específicas que se excluyen de este tratamiento.\n",
    "\n",
    "El notebook también detalla la aplicación de condiciones específicas a ciertas columnas para ajustar los datos antes de la imputación. Estas condiciones están relacionadas con aspectos de salud ginecológica, cáncer colorectal, hábitos de fumar, cáncer y manejo del dolor, entre otros. Esto permite una manipulación detallada y contextual de los datos, preparándolos para una imputación más precisa.\n",
    "\n",
    "Para la imputación de valores nulos, se utiliza el `Imputer` de Spark ML, configurado para usar la mediana como estrategia de imputación. Esta elección ayuda a mantener la robustez del análisis frente a datos atípicos. Antes de aplicar el `Imputer`, se calculan y aplican valores medios para columnas específicas como `CHILDREN` y `_BMI5`, demostrando un enfoque de imputación personalizado antes de la aplicación del imputer generalizado.\n",
    "\n",
    "Finalmente, el notebook concluye con la imputación de valores nulos utilizando la mediana para el resto de las columnas que aún contienen valores nulos, seguido de una revisión final para identificar columnas que aún puedan tener valores nulos. Los datos imputados se guardan en un archivo CSV, preparando el conjunto de datos para el análisis de clustering.\n",
    "\n",
    "Este enfoque meticuloso para preparar los datos de BRFSS para el análisis de clustering no solo mejora la calidad de los datos sino que también asegura que las inferencias y patrones descubiertos sean representativos y útiles para informar decisiones relacionadas con la salud pública."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64ab79-9c35-48b6-b069-92f5cf0d77a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
